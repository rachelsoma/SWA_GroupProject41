---
Title: "Analysis of J.K. Rowling. Part B"
output:
  html_document: default
  pdf_document: default
---

Cover Sheet
========================================================


By including this statement, we, all the students listed in the table
below, declare that:

- We hold a copy of this assignment if the original is lost or damaged.

- We hereby certify that no part of this assignment has been copied from
  any other student's work or from any other source except where due
  acknowledgement is made in the assignment.

- No part of the assignment has been written for us by any other person
  except where collaboration has been authorised by the unit coordinator.

- We are aware that this work may be reproduced and submitted to plagiarism
  detection software programs for the purpose of detecting possible
  plagiarism; this software may retain a copy on its database for future
  plagiarism checking.

- We hereby certify that no part of this assignment or product has been
  submitted by any of us in another (previous or current) assessment, except
  where appropriately referenced, and with prior permission from the unit
  coordinator for this unit.

- We hereby certify that we have read and understand what the University
  considers to be academic misconduct, and that we are aware of thes
  penalties that may be imposed for academic misconduct.

Name                  | Student Number  | Contribution (%)
----------------------|-----------------|-----------------
Rachel Hardie         |  18820821       |   25%
Dylan Wang            |  18998014       |   25%
Dylan Yoo             |  18640377       |   25%
Sreenath Ramachandran |  18878716       |   25%

<div style="page-break-before:always;"></div>

```{r setup, message=FALSE, warning=FALSE}
library("tm")
library("rtweet")
library("twitteR")
library("igraph")
library("knitr")
tweets=read.csv("SWAProject.csv")
```

We then constructed a document-term matrix using TFIDF weighting to describe the frequency of terms in the tweets we had collected.

```{r DTM, results='hide', message=FALSE, warning=FALSE}
corpus=Corpus(VectorSource(tweets$text))
corpus = tm_map(corpus, function(x) iconv(x, to = 'UTF8', sub = 'byte'))
corpus = tm_map(corpus, function(x) iconv(x, to = 'ASCII', sub = ' '))
corpus = tm_map(corpus,removeNumbers)
corpus = tm_map(corpus, removeWords,c(stopwords(),"J.K. Rowling","https", "t.co"))
corpus = tm_map(corpus,removePunctuation)
corpus = tm_map(corpus,stripWhitespace)
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, removeWords,c(stopwords(),"jk","https", "t.co","rowl","jkrowl",
                                      "will","like","just","doe","far","quot","look",
                                      "take","make","jaqkcpmtg","ygorfremo","ask","peopl",
                                      "next","twitter","peopl","new","write","charact","got",
                                      "ohhgmljqrm","say","defend","respond", "vrmgsnrsa",
                                      "bbepgeik","nkuwxgsn","novrijqr","nlrbgguhxt"))
dtm = DocumentTermMatrix(corpus)
tweet.wdtm = weightTfIdf(dtm)
tweet.matrix = as.matrix(tweet.wdtm)
```

## Finding the similarity index

To find the cosine similarity matrix we first find the normalised tweet matrix.

```{r cosine}
#Find similarity matrix
S=tweet.matrix%*%t(tweet.matrix)
#to find the cosine similarity matrix we need  the normalised tweet matrix.
norm.tweet.matrix = diag(1/sqrt(rowSums(tweet.matrix^2))) %*% tweet.matrix
#cosine similarity
CS=norm.tweet.matrix%*%t(norm.tweet.matrix)

head(S)[1:20]
head(CS)[1:20]
```
##Difference between Cosine similarity and S
Cosine similarity gives the angle between the documents. The similarity matrix is more like the magnitude of the difference between the documents whereas the cosine similarity matrix gives the direction.Cosine similarity of the documents will be between 0 and 1. 
##8.4.2
As the histogram of retweet count is exponenetial we take logarithm of retweet counts we take the log of retweet count+1 so as to eliminate log 0 from the data


```{r retweet_log}
#8.4.2
retweetCount=tweets$retweet_count

hist(retweetCount,col=heat.colors(5))
retweet.log=log(retweetCount+1)

hist(retweet.log,col=heat.colors(5))
```



##8.4.3

To make the graph simpler we are taking the top 20 retweeted tweets.


```{r network_graphs}
graph=graph.adjacency(S,weighted = TRUE)

plot(simplify(graph),layout = layout.drl, vertex.size=retweet.log*.9, vertex.label="",vertex.color=heat.colors(10),edge.width=0.5, edge.arrow.size=0)

id=order(retweet.log,decreasing = TRUE)[1:20]
tweets.imp=tweets[id,]
retweetCount.imp=tweets.imp$retweet_count
#retweetCount.imp
tweet.imp=tweet.matrix[id,]
s.imp=tweet.imp%*%t(tweet.imp)
set.seed(1500)
graph1=graph.adjacency(s.imp,weighted = TRUE)
plot(simplify(graph1),layout=layout.auto,
     vertex.size=retweet.log*.9, edge.width=0.5,
     edge.arrow.size=0,vertex.label="",vertex.color=heat.colors(5))
```


###Results

Connected tweets mostly are the same tweets retweeted by different users.


##8.5.1
###Degree centrality
```{r degree_centrality, warning=FALSE}

degCentrality=degree(graph)
topTweetsDegree=order(degCentrality,decreasing = TRUE)[1:10]
tweets$text[topTweetsDegree]

```

###Closeness centrality 

```{r closeness_centrality, warning=FALSE}
closenessCentrality=closeness(graph)
topTweetsCloseness=order(closeness(graph),decreasing = TRUE)[1:10]
tweets$text[topTweetsCloseness]
```

###Betweenness centrality 

```{r betweenness, warning=FALSE}
betweennessCentrality=betweenness(graph)
topTweetsBetweenness=order(betweenness(graph),decreasing = TRUE)[1:10]
tweets$text[topTweetsBetweenness]
```

#8.5.2 Page rank to calculate the most influential tweets
```{r page_rank, warning=FALSE}
adjacency.to.probability = function(A) {
  cols = ncol(A)
  for (a in 1:cols) {
    A[, a] = normalise(A[, a])
  }
  return(A)
}
normalise=function(x){
  if(sum(x)!=0){
    x=x/sum(x)
  }else{
    x=x
  }
  return(x)
}
T = adjacency.to.probability(S)
J = matrix(rep(1/1000, 1000 * 1000), 1000, 1000)
alpha=0.8
M = alpha * T + (1 - alpha) * J
M = adjacency.to.probability(M)
#Power method to find stationary distribution
#function to calculate Euclidean distance between two vectors.
differenceEuc=function(x,y){
  return(sqrt(sum((x-y)^2)))
}
stationary.distribution = function(T) {
  # first create the initial state distribution
  n = ncol(T)
  p = rep(0, n)
  p[1] = 1
  
  # now take a random walk until the state distribution reaches the
  # stationary distribution.
  p.old = rep(0, n)
  while (differenceEuc(p, p.old) > 1e-06) {
    p.old = p
    p = T %*% p.old
  }
  return(p)
}

p = stationary.distribution(M)
influentialTweets=order(p,decreasing = TRUE)[1:11]
#took 11 to get 10 distinct users as one user was repeat in top10.
tweets$text[influentialTweets]

```
###8.5.3 Influential Users
```{r influencers, warning=FALSE}
users=tweets$screen_name[influentialTweets]
users

```


#8.5.4 influence ratio
```{r influence_ratio, warning=FALSE}
InfluenceRatio= tweets$followers_count[influentialTweets]/
                tweets$friends_count[influentialTweets]

influence <- unique(data.frame(users,InfluenceRatio))
names(influence) <- c("User Names","Influence Ratio")
influence

#median followers in sample
followers.median=median(tweets$followers_count)
influenceRatio.median=median(InfluenceRatio)
```

#8.5.4 Activity measures
```{r activities, warning=FALSE}
ActivityMeasure=tweets$statuses_count[influentialTweets]
activity <- data.frame(users,ActivityMeasure)
names(activity) <- c("User Names","Activity Measure")
plot(activity,pch = 20,lwd=5)
text(users, ActivityMeasure, labels=users, cex= 0.7, pos=4)
```

#8.5.5

```{r echo=FALSE}
plot(InfluenceRatio,ActivityMeasure,col=heat.colors(20),pch=20, text(InfluenceRatio,ActivityMeasure,labels = users,cex = .7,pos=3 ))+
abline(v=influenceRatio.median,col="blue")+title(main="Activity Measure and Influence Ratio of influential Tweet authors",sub="Median for all samples shown with blue line",cex.sub = 0.75,col.sub="blue")

```



##Findings
The most influential user 'culturalkumite' is a bot. The high influential ratio is as it has 61 followers and it follows only 1 user.This may be due due to the fact that it tweets "versus" questions about authors, film, culture and trending topics. Other users of influential tweets do not have a very high influence ratio and are most likely fans of  J.K.Rowling's work.

###Conclusion
J.K Rowling is a very popular author. Tweets about her often changes. Of the tweets we have downloaded most of them were about her creations. Most of the influential tweets were about the movie Fantastic beasts. There were some users who were accusing Rowling of Racism in the charecters she created, particularly for the 'nagini' role in the film Fantastic Beasts. 